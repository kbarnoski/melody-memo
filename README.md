# Resonance

Your personal audio workspace — analyze, visualize, and explore your music.

Resonance is an AI-powered piano voice memo platform that transforms raw musical recordings into structured, analyzable, and developable musical ideas for pianists and composers.

## Features

### Recording Management
- Multi-file upload with drag-and-drop (M4A, MP3, WAV)
- Searchable library with metadata (duration, key, tempo, analysis status)
- Tags with AND-logic filtering and named collections with drag-and-drop reordering
- Inline editing with autosave for titles and descriptions

### Audio Playback & Visualization
- Bar-style waveform player (WaveSurfer.js) with play/pause, skip, and time tracking
- Server-side FFmpeg transcoding for iPhone Lossless (ALAC) to AAC
- HTTP range request streaming
- 8 full-screen WebGL shader visualizers: Mandala, Cosmos, Neon, Liquid, Sacred, Ethereal, Fractal, and Warp

### AI Music Analysis
- **Note transcription** via Spotify's Basic Pitch (client-side TensorFlow.js)
- **Key detection** using the Krumhansl-Schmuckler algorithm with confidence scoring
- **Chord detection** with inversion awareness via Tonal.js
- **Tempo estimation** via autocorrelation on note onsets (40–240 BPM)
- **Time signature detection** through accent pattern analysis
- **Harmonic rhythm analysis** and recurring progression identification
- **AI teaching summary** generated by Claude — covers key center, sections, chord vocabulary, harmonic highlights, rhythm and feel, and relearning tips
- **MIDI export** of transcribed notes

### Music Visualizations
- **Chord timeline**: color-coded bar with synced playhead and interactive seeking
- **Piano roll**: SVG-based note display with velocity-scaled opacity and active note highlighting
- **Markers**: time-stamped bookmarks on the waveform with custom labels, clickable seeking, and database persistence

### AI Chat
- **Per-recording chat**: streaming conversation grounded in analysis data for music theory coaching and development suggestions
- **Compare chat**: side-by-side analysis identifying shared progressions, key relationships, and medley potential
- **Library chat**: cross-library conversation about patterns, tendencies, and compositional style

### Insights Dashboard
- Quick stats: total recordings, analysis completion, average tempo, key distribution
- Musical DNA: favorite keys, chord vocabulary, tempo range, harmonic tendencies
- Charts for key distribution and chord frequency
- Recurring progression patterns and pairwise recording similarity
- Claude-generated library summary with musical clusters and development suggestions

### Compare Mode
- Side-by-side metric comparison (key, tempo, time signature, note range, chords)
- Full analysis display for both recordings
- Dedicated AI chat for cross-recording analysis

### Public Sharing
- UUID-based share links for individual recordings
- Public view with metadata, audio player, and analysis summary — no login required

## Tech Stack

| Layer | Technology |
|---|---|
| Framework | Next.js 15 (App Router, TypeScript, React 19) |
| UI | shadcn/ui, Tailwind CSS, Lucide icons |
| Auth & Database | Supabase (Auth, PostgreSQL, Storage) |
| AI | Vercel AI SDK + Claude |
| Audio Analysis | @spotify/basic-pitch, TensorFlow.js, Tonal.js |
| Audio Playback | WaveSurfer.js v7 |
| Transcoding | FFmpeg (server-side) |
| Visualizations | Three.js, WebGL shaders, SVG |
| MIDI | @tonejs/midi |
| Hosting | Vercel |

## Getting Started

### Prerequisites
- Node.js 18+
- A Supabase project
- An Anthropic API key (for Claude)

### Environment Variables

```
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
ANTHROPIC_API_KEY=your_anthropic_api_key
```

### Setup

```bash
npm install
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to get started.

### Database

Apply the schema to your Supabase project:

```bash
# Full schema
psql -f supabase-schema.sql

# v2 migration (if upgrading)
psql -f supabase-v2-migration.sql
```

All tables enforce row-level security so users can only access their own data.

## Project Structure

```
src/
├── app/
│   ├── (app)/              # Protected routes (require auth)
│   │   ├── collections/    # Collection management
│   │   ├── compare/        # Side-by-side comparison
│   │   ├── insights/       # Dashboard with library stats
│   │   ├── library/        # Main recording library
│   │   ├── recording/[id]/ # Single recording detail
│   │   └── upload/         # Multi-file upload
│   ├── api/                # API routes (analysis, audio, chat, insights)
│   ├── login/              # Auth pages
│   ├── signup/
│   └── share/[token]/      # Public share view
├── components/
│   ├── analysis/           # Chord timeline, piano roll, MIDI export
│   ├── audio/              # Waveform player, visualizer
│   ├── chat/               # Chat UI, messages, prompts
│   ├── collections/        # Collection management
│   ├── insights/           # Dashboard charts, similarity, summaries
│   ├── markers/            # Marker management
│   ├── recordings/         # Recording cards and library
│   ├── tags/               # Tag UI
│   └── ui/                 # shadcn components
├── lib/
│   ├── ai/                 # System prompt builders
│   ├── audio/              # Transcription, analysis, MIDI
│   ├── analysis/           # Cross-recording analysis
│   └── supabase/           # Client and server utilities
└── middleware.ts            # Auth middleware
```

## Deploy

Deploy to Vercel with one click or via the CLI:

```bash
npm run build
vercel deploy
```

Set your environment variables in the Vercel dashboard.
